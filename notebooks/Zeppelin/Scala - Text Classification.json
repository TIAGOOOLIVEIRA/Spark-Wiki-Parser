{"paragraphs":[{"text":"%md\n\n## Basic Text Logistic Regression Classification\n\nFor this first example we pull in text from two headers: Early life and death.  We then apply a logistic regression model to predict if a text is talking about someone's early life or later life.\n\nThis is not meant to be an in depth introduction to natural language processing.  Rather a starting point for utilizing wikipedia data and Spark's ML lib.\n\nAdapted from: [Mastering Spark: Example Text Classification](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-mllib/spark-mllib-pipelines-example-classification.html)\n\nSee also:\n\n[Tokenization](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n\n[Feature hashing](https://en.wikipedia.org/wiki/Feature_hashing)","user":"anonymous","dateUpdated":"2017-11-29T04:03:13+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Basic Text Logistic Regression Classification</h2>\n<p>For this first example we pull in text from two headers: Early life and death.  We then apply a logistic regression model to predict if a text is talking about someone's early life or later life.</p>\n<p>This is not meant to be an in depth introduction to natural language processing.  Rather a starting point for utilizing wikipedia data and Spark's ML lib.</p>\n<p>Adapted from: <a href=\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-mllib/spark-mllib-pipelines-example-classification.html\">Mastering Spark: Example Text Classification</a></p>\n<p>See also:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization\">Tokenization</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Feature_hashing\">Feature hashing</a></p>\n"}]},"apps":[],"jobName":"paragraph_1511922392982_1457322488","id":"20171129-022632_336328370","dateCreated":"2017-11-29T02:26:32+0000","dateStarted":"2017-11-29T04:03:13+0000","dateFinished":"2017-11-29T04:03:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4841"},{"text":"// Update S3 Info\nval bucketName = \"bnielsenemr\"\nval destFolder = \"wkpDb\"\n\n// Concat values\nval s3 = s\"s3://$bucketName/\"\nval destDB = s3 + destFolder + \"/\"\n\nspark.read.parquet(destDB + \"wkp_headers.parquet\").createOrReplaceTempView(\"headers\")\nspark.read.parquet(destDB + \"wkp_text.parquet\").createOrReplaceTempView(\"text\")","user":"anonymous","dateUpdated":"2017-11-29T03:46:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"bucketName: String = bnielsenemr\ndestFolder: String = wkpDb\ns3: String = s3://bnielsenemr/\ndestDB: String = s3://bnielsenemr/wkpDb/\n"}]},"apps":[],"jobName":"paragraph_1511922398042_2131033136","id":"20171129-022638_1384815804","dateCreated":"2017-11-29T02:26:38+0000","dateStarted":"2017-11-29T03:46:51+0000","dateFinished":"2017-11-29T03:47:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4842"},{"text":"%spark.sql\nCREATE OR REPLACE TEMPORARY VIEW trainingSet\nAS\nSELECT\n    txt.text,\n    CASE WHEN hdr.title = 'Early life' THEN 1.0 ELSE 0.0 END as label\nFROM\n    headers hdr\nJOIN\n    text txt\n    ON  txt.parentArticleId = hdr.parentArticleId\n    AND txt.parentHeaderId = hdr.headerId\n\nWHERE\n    hdr.title IN('Early life', 'Death')\nAND LENGTH(txt.text) > 75\nLIMIT 1000","user":"anonymous","dateUpdated":"2017-11-29T03:47:48+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":""}]},"apps":[],"jobName":"paragraph_1511922729189_-1912201110","id":"20171129-023209_1059571627","dateCreated":"2017-11-29T02:32:09+0000","dateStarted":"2017-11-29T03:47:48+0000","dateFinished":"2017-11-29T03:47:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4843"},{"text":"import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.Pipeline\n\n// Create training and set\nval labeledDf = spark.table(\"trainingSet\")\nval Array(trainDF, testDF) = labeledDf.randomSplit(Array(0.75, 0.25))\n\n// Split into individual words\nval tokenizer = new Tokenizer()\n  .setInputCol(\"text\")\n  .setOutputCol(\"words\")\n\n// Hash words\nval hashingTF = new HashingTF()\n    .setInputCol(tokenizer.getOutputCol)\n    .setOutputCol(\"features\")\n    .setNumFeatures(5000)\n\n// Create logistic regression model\nval lr = new LogisticRegression().setMaxIter(20).setRegParam(0.01)\n\nval pipeline = new Pipeline().setStages(Array(tokenizer, hashingTF, lr))\n\nval model = pipeline.fit(spark.table(\"trainingSet\"))\n\nval trainPredictions = model.transform(trainDF)\nval testPredictions = model.transform(testDF)","user":"anonymous","dateUpdated":"2017-11-29T04:00:39+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.Pipeline\nlabeledDf: org.apache.spark.sql.DataFrame = [text: string, label: decimal(2,1)]\ntrainDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [text: string, label: decimal(2,1)]\ntestDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [text: string, label: decimal(2,1)]\ntokenizer: org.apache.spark.ml.feature.Tokenizer = tok_95f1c0e42b17\nhashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_fcbd473241a9\nlr: org.apache.spark.ml.classification.LogisticRegression = logreg_9f588eb40435\npipeline: org.apache.spark.ml.Pipeline = pipeline_aa727b822377\nmodel: org.apache.spark.ml.PipelineModel = pipeline_aa727b822377\ntrainPredictions: org.apache.spark.sql.DataFrame = [text: string, label: decimal(2,1) ... 5 more fields]\ntestPredictions: org.apache.spark.sql.DataFrame = [text: string, label: decimal(2,1) ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1511925623057_-664536001","id":"20171129-032023_1752740902","dateCreated":"2017-11-29T03:20:23+0000","dateStarted":"2017-11-29T04:00:39+0000","dateFinished":"2017-11-29T04:01:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4844"},{"text":"trainPredictions.filter(\"label != prediction\").show()","user":"anonymous","dateUpdated":"2017-11-29T04:10:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511927124372_16013640","id":"20171129-034524_858054624","dateCreated":"2017-11-29T03:45:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4846","dateFinished":"2017-11-29T04:12:23+0000","dateStarted":"2017-11-29T04:10:29+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|                text|label|               words|            features|       rawPrediction|         probability|prediction|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n|After Seiheitai's...|  0.0|[after, seiheitai...|(5000,[234,312,37...|[-1.1728619349365...|[0.23633806572647...|       1.0|\n|Aladi Aruna  was ...|  0.0|[aladi, aruna, , ...|(5000,[48,87,128,...|[-1.7766593759146...|[0.14471612383341...|       1.0|\n|Alfred Bazin had ...|  0.0|[alfred, bazin, h...|(5000,[193,208,22...|[-2.0471452553246...|[0.11434115531420...|       1.0|\n|Bandyopadhyay suf...|  0.0|[bandyopadhyay, s...|(5000,[76,234,468...|[-1.1185600399778...|[0.24627847902571...|       1.0|\n|Blenk died eleven...|  0.0|[blenk, died, ele...|(5000,[234,347,35...|[-1.2373366703892...|[0.22489991701200...|       1.0|\n|Brad died aged 62...|  0.0|[brad, died, aged...|(5000,[101,164,19...|[-1.2477988846512...|[0.22308139498189...|       1.0|\n|Brecht died on 14...|  0.0|[brecht, died, on...|(5000,[22,61,103,...|[-1.2570633185558...|[0.22147983979223...|       1.0|\n|Brother Roger's g...|  0.0|[brother, roger's...|(5000,[68,133,145...|[-2.7646044086441...|[0.05926712774939...|       1.0|\n|Burke was born at...|  1.0|[burke, was, born...|(5000,[49,76,128,...|[2.48593721126768...|[0.92315006714219...|       0.0|\n|Corporal Thomas J...|  0.0|[corporal, thomas...|(5000,[57,117,126...|[-1.7757968299067...|[0.14482291677722...|       1.0|\n|Cottee was surviv...|  0.0|[cottee, was, sur...|(5000,[234,240,46...|[-2.1268620505742...|[0.10651325609419...|       1.0|\n|Cuffe was found d...|  0.0|[cuffe, was, foun...|(5000,[234,1299,1...|[-0.3502572708943...|[0.41332003495154...|       1.0|\n|Empress Nam Phươn...|  0.0|[empress, nam, ph...|(5000,[234,563,71...|[-0.0812263517965...|[0.47970456945507...|       1.0|\n|For many years, T...|  0.0|[for, many, years...|(5000,[3,57,64,72...|[-3.7360362397927...|[0.02329294502082...|       1.0|\n|GG Allin's grave ...|  0.0|[gg, allin's, gra...|(5000,[87,92,94,2...|[-3.5593154239716...|[0.02767083499595...|       1.0|\n|Grave marker\nOn M...|  0.0|[grave, marker, o...|(5000,[142,151,15...|[-0.6118316187901...|[0.35164149421394...|       1.0|\n|Grave of Lojze Gr...|  0.0|[grave, of, lojze...|(5000,[39,67,72,8...|[-1.1560918042873...|[0.23937814981745...|       1.0|\n|Grave of Sergei S...|  0.0|[grave, of, serge...|(5000,[51,87,188,...|[-0.1688776756682...|[0.45788063606139...|       1.0|\n|He committed suic...|  0.0|[he, committed, s...|(5000,[3,39,56,23...|[-0.6260716621598...|[0.34840180923802...|       1.0|\n|He died at Tufton...|  0.0|[he, died, at, tu...|(5000,[234,285,71...|[-0.6499074011652...|[0.34301040456566...|       1.0|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511927460609_-1722390805","id":"20171129-035100_996665696","dateCreated":"2017-11-29T03:51:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5515","text":"import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.param.ParamMap\n\nval evaluator = new BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")\nval evaluatorParams = ParamMap(evaluator.metricName -> \"areaUnderROC\")\nval areaTrain = evaluator.evaluate(trainPredictions, evaluatorParams)\nval areaTest = evaluator.evaluate(testPredictions, evaluatorParams)","dateUpdated":"2017-11-29T04:02:22+0000","dateFinished":"2017-11-29T04:04:15+0000","dateStarted":"2017-11-29T04:02:22+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.param.ParamMap\nevaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_b677f3909bfa\nevaluatorParams: org.apache.spark.ml.param.ParamMap =\n{\n\tbinEval_b677f3909bfa-metricName: areaUnderROC\n}\nareaTrain: Double = 0.9653650351783705\nareaTest: Double = 0.9661991038379115\n"}]}},{"text":"%spark.sql\n","user":"anonymous","dateUpdated":"2017-11-29T04:18:56+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511929017379_944906398","id":"20171129-041657_96462255","dateCreated":"2017-11-29T04:16:57+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6201"}],"name":"Scala - Text Classification","id":"2D2QWCSNZ","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}